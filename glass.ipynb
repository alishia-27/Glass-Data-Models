{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0jAhKkJ0gy0P",
        "outputId": "20ad332b-f756-49b2-8271-ee40655e4f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Original Data =======\n",
            "Results for Random Forest on Original data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.74      0.89      0.81        19\n",
            "           2       0.75      0.65      0.70        23\n",
            "           3       0.67      0.50      0.57         4\n",
            "           5       0.75      0.50      0.60         6\n",
            "           6       0.75      1.00      0.86         3\n",
            "           7       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.77        65\n",
            "   macro avg       0.76      0.76      0.75        65\n",
            "weighted avg       0.77      0.77      0.76        65\n",
            "\n",
            "[[17  2  0  0  0  0]\n",
            " [ 4 15  1  1  1  1]\n",
            " [ 2  0  2  0  0  0]\n",
            " [ 0  3  0  3  0  0]\n",
            " [ 0  0  0  0  3  0]\n",
            " [ 0  0  0  0  0 10]]\n",
            "\n",
            "\n",
            "Results for SVM on Original data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      0.84      0.74        19\n",
            "           2       0.64      0.70      0.67        23\n",
            "           3       0.00      0.00      0.00         4\n",
            "           5       1.00      0.50      0.67         6\n",
            "           6       0.50      0.67      0.57         3\n",
            "           7       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.71        65\n",
            "   macro avg       0.63      0.60      0.60        65\n",
            "weighted avg       0.69      0.71      0.69        65\n",
            "\n",
            "[[16  3  0  0  0  0]\n",
            " [ 6 16  0  0  1  0]\n",
            " [ 2  2  0  0  0  0]\n",
            " [ 0  3  0  3  0  0]\n",
            " [ 0  1  0  0  2  0]\n",
            " [ 0  0  0  0  1  9]]\n",
            "\n",
            "\n",
            "Results for KNN on Original data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.57      0.84      0.68        19\n",
            "           2       0.59      0.57      0.58        23\n",
            "           3       0.00      0.00      0.00         4\n",
            "           5       0.67      0.33      0.44         6\n",
            "           6       1.00      0.67      0.80         3\n",
            "           7       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.65        65\n",
            "   macro avg       0.62      0.55      0.57        65\n",
            "weighted avg       0.62      0.65      0.62        65\n",
            "\n",
            "[[16  3  0  0  0  0]\n",
            " [ 9 13  0  1  0  0]\n",
            " [ 2  2  0  0  0  0]\n",
            " [ 1  3  0  2  0  0]\n",
            " [ 0  0  0  0  2  1]\n",
            " [ 0  1  0  0  0  9]]\n",
            "\n",
            "\n",
            "======= Oversampled Data =======\n",
            "Results for Random Forest on Oversampled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.78      0.95      0.86        19\n",
            "           2       0.79      0.65      0.71        23\n",
            "           3       0.50      0.50      0.50         4\n",
            "           5       0.67      0.67      0.67         6\n",
            "           6       0.75      1.00      0.86         3\n",
            "           7       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.78        65\n",
            "   macro avg       0.75      0.78      0.76        65\n",
            "weighted avg       0.79      0.78      0.78        65\n",
            "\n",
            "[[18  1  0  0  0  0]\n",
            " [ 3 15  2  2  1  0]\n",
            " [ 2  0  2  0  0  0]\n",
            " [ 0  2  0  4  0  0]\n",
            " [ 0  0  0  0  3  0]\n",
            " [ 0  1  0  0  0  9]]\n",
            "\n",
            "\n",
            "Results for SVM on Oversampled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.65      0.68      0.67        19\n",
            "           2       0.67      0.61      0.64        23\n",
            "           3       0.14      0.25      0.18         4\n",
            "           5       0.80      0.67      0.73         6\n",
            "           6       0.33      0.33      0.33         3\n",
            "           7       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.65        65\n",
            "   macro avg       0.60      0.57      0.58        65\n",
            "weighted avg       0.68      0.65      0.66        65\n",
            "\n",
            "[[13  3  3  0  0  0]\n",
            " [ 5 14  3  0  1  0]\n",
            " [ 2  1  1  0  0  0]\n",
            " [ 0  2  0  4  0  0]\n",
            " [ 0  1  0  1  1  0]\n",
            " [ 0  0  0  0  1  9]]\n",
            "\n",
            "\n",
            "Results for KNN on Oversampled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.64      0.74      0.68        19\n",
            "           2       0.76      0.57      0.65        23\n",
            "           3       0.20      0.25      0.22         4\n",
            "           5       0.75      1.00      0.86         6\n",
            "           6       0.60      1.00      0.75         3\n",
            "           7       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.69        65\n",
            "   macro avg       0.66      0.73      0.68        65\n",
            "weighted avg       0.72      0.69      0.69        65\n",
            "\n",
            "[[14  3  2  0  0  0]\n",
            " [ 6 13  2  1  1  0]\n",
            " [ 2  1  1  0  0  0]\n",
            " [ 0  0  0  6  0  0]\n",
            " [ 0  0  0  0  3  0]\n",
            " [ 0  0  0  1  1  8]]\n",
            "\n",
            "\n",
            "======= Undersampled Data =======\n",
            "Results for Random Forest on Undersampled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.60      0.47      0.53        19\n",
            "           2       0.60      0.39      0.47        23\n",
            "           3       0.17      0.50      0.25         4\n",
            "           5       0.67      1.00      0.80         6\n",
            "           6       0.60      1.00      0.75         3\n",
            "           7       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.58        65\n",
            "   macro avg       0.61      0.71      0.63        65\n",
            "weighted avg       0.64      0.58      0.59        65\n",
            "\n",
            "[[9 5 5 0 0 0]\n",
            " [4 9 5 3 2 0]\n",
            " [2 0 2 0 0 0]\n",
            " [0 0 0 6 0 0]\n",
            " [0 0 0 0 3 0]\n",
            " [0 1 0 0 0 9]]\n",
            "\n",
            "\n",
            "Results for SVM on Undersampled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.44      0.37      0.40        19\n",
            "           2       0.59      0.43      0.50        23\n",
            "           3       0.18      0.50      0.27         4\n",
            "           5       0.67      1.00      0.80         6\n",
            "           6       0.50      0.67      0.57         3\n",
            "           7       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.54        65\n",
            "   macro avg       0.56      0.63      0.57        65\n",
            "weighted avg       0.59      0.54      0.55        65\n",
            "\n",
            "[[ 7  7  5  0  0  0]\n",
            " [ 7 10  4  1  1  0]\n",
            " [ 2  0  2  0  0  0]\n",
            " [ 0  0  0  6  0  0]\n",
            " [ 0  0  0  1  2  0]\n",
            " [ 0  0  0  1  1  8]]\n",
            "\n",
            "\n",
            "Results for KNN on Undersampled data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.48      0.68      0.57        19\n",
            "           2       0.78      0.30      0.44        23\n",
            "           3       0.18      0.50      0.27         4\n",
            "           5       0.80      0.67      0.73         6\n",
            "           6       0.75      1.00      0.86         3\n",
            "           7       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.58        65\n",
            "   macro avg       0.67      0.68      0.63        65\n",
            "weighted avg       0.69      0.58      0.59        65\n",
            "\n",
            "[[13  1  5  0  0  0]\n",
            " [10  7  4  1  1  0]\n",
            " [ 2  0  2  0  0  0]\n",
            " [ 2  0  0  4  0  0]\n",
            " [ 0  0  0  0  3  0]\n",
            " [ 0  1  0  0  0  9]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Loading the dataset\n",
        "url = 'glass.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = data.drop('Type', axis=1)\n",
        "y = data['Type']\n",
        "\n",
        "# Normalizing the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Defining the sampling strategies\n",
        "oversample = SMOTE(k_neighbors=2)\n",
        "undersample = RandomUnderSampler()\n",
        "\n",
        "# Applying oversampling\n",
        "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "# Applying undersampling\n",
        "X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "# Training and evaluating models\n",
        "for sampling_type, X_sample, y_sample in [('Original', X_train, y_train), ('Oversampled', X_over, y_over), ('Undersampled', X_under, y_under)]:\n",
        "    print(f\"======= {sampling_type} Data =======\")\n",
        "    # Initialize the classifiers\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    svm = SVC(random_state=42)\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Training the models\n",
        "    rf.fit(X_sample, y_sample)\n",
        "    svm.fit(X_sample, y_sample)\n",
        "    knn.fit(X_sample, y_sample)\n",
        "\n",
        "    # Models to evaluate\n",
        "    models = {'Random Forest': rf, 'SVM': svm, 'KNN': knn}\n",
        "\n",
        "    # Making predictions and evaluating the models\n",
        "    for name, model in models.items():\n",
        "        print(f\"Results for {name} on {sampling_type} data:\")\n",
        "        predictions = model.predict(X_test)\n",
        "        print(classification_report(y_test, predictions))\n",
        "        print(confusion_matrix(y_test, predictions))\n",
        "        print(\"\\n\")"
      ]
    }
  ]
}